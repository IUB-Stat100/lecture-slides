---
title: "Stat100 Concepts"
author: "DJM"
date: "As of: `r Sys.Date()`"
output: pdf_document
---


Out of how many
: Numbers are magnitudes. It often helps to interpret if we convert these to ratios. For example, rather than knowing the number of murders in a city it may help to compare to the population of the city (murders per 100,000 residents, say).

Compare with rates, but be careful
: Related to "out of how many", it's often more useful to examine rates. But these can be counterintuitive if "how many" is relatively small.

Clumping/streaks
: Pure random process produce streaks or clumps. This isn't necessarily a sign of some thing real. Think a coin that lands heads 5 times in a row out of 10 or a roulette wheel that lands on "odds" 6 times.

Independence/Dependence
: It's easy to calculate the probabilities of independent events all occurring: just multiply. But be careful to make sure the events are independent!

Sunk costs
: Be wary of making decisions based on past decisions you can't change. Don't bet in poker based on past losses. Don't stay with your significant other just because you've been together for a while.

Decision making with uncertainty
: Try to determine the utility you'll earn for each possible outcome. How likely are those outcomes? Make the decision with a higher expected utility.

Regression to the mean
: Other things equal, performance below the average is likely to be followed by relatively higher performance. Performance above the average is likely to be followed by relatively lower performance.

Color scaling
: Be aware of the point you're trying to make. Is it apparent? Be aware of colorblindness (about 10% of men and 4% of women).

Expected value
: Mathematically, the sum of all potential values weighted by the probability of seeing those values. For example, the expected number of heads in 2 flips of a fair coin is
$$EV = 0\times \frac{1}{4} + 1\times \frac{2}{4} + 2\times \frac{1}{4} = 1$$

Law of large numbers
: As you repeat a process over and over and over forever, the running average will get closer and closer to the expected value.

Simpson's paradox
: a trend appears in several different groups of data but disappears or reverses when these groups are combined

Hypothesis test
: if the _null hypothesis_ is true, would we expect to see data like this? If yes, then stick with the status quo. If no, then we reject the null in favor of the _alternative_.

Null hypothesis
: The current state of our understanding. The presumed truth. The thing we want to falsify.

Alternative hypothesis
: The thing we wish to prove. Think _null_ $=$ innocent, _alternative_ $=$ guilty.

P-value
: Given that the null is true, what is the probability of our observed data, or something more extreme

Statistical significance
: if the p-value is "small enough", we call the effect "statistically significant"

Margin of error
: we have an estimate of something (say a poll that shows 30% support), but how much might that estimate vary? This range is the "margin of error"

Graphics
: scaling, coloring, axes, percentages, etc. Does this graphic make the point clearly? Does it obscure alternative interpretations to manipulate?

Proportionality principle
: If various alternatives are equally likely, and then some event is observed, the updated probabilities for the alternatives are proportional to the probabilities that the observed event _would_ have occurred under those alternatives.

Sample space
: An enumeration of the possible outcomes of a process.

Foxy forecasting
: drawing on a wide variety of experiences and evidence to make predictions rather than using the lens of a single guiding idea

Reproducible research
: Work which can be easily replicated by another researcher or group by taking in the original data and running a series of well-described codes

Peer review
: The process by which other experts evaluate and ascertain whether the results described can be widely accepted within a research community as valid

Mean vs Median
: The mean or average is the sum of all the observations divided by the number of observations. The median is the value that splits the data into two equal sized parts. The mean is influenced by very large or small values, outliers, while the median is not. The median is more _robust_ to abberant values.

Forecast horizon
: How far in the future you're making predictions. Generally, the farther ahead you try to predict, the more uncertain you are.

Forecast uncertainty
: When you make a prediction, you want to think about sources and sizes of possible errors. How accurate is your prediction?

Model averaging
: Combining information from lots of different sources to make a prediction. This is "foxy".

Histogram
: A graphical display of possible values along with the observed frequencies of those values. For example:

```{r, fig.width=8, fig.height=4, out.width="4in", out.height="2in", fig.align='center', echo=FALSE, message=FALSE}
library(tidyverse)
kid = read.csv(url('https://raw.githubusercontent.com/robinryder/BDA-kidney/master/KidneyCancerClean.csv'), skip=4)
kid = kid %>% mutate(
  deaths = dc+dc.2, avg_pop = (pop + pop.2)/2, deathrate = deaths / avg_pop,
  low_rate = deathrate <= quantile(deathrate, .1),
  high_rate = deathrate >= quantile(deathrate, .9),
  ratebayes = (deaths + 15) / (avg_pop + 2e5),
  lowbayes = ratebayes <= quantile(ratebayes, .1),
  highbayes = ratebayes >= quantile(ratebayes, .9),
  ) %>% as_tibble() 
kid %>% ggplot(aes(deathrate*10000)) + geom_histogram(fill='red', color='blue') +
  cowplot::theme_cowplot() + scale_y_continuous(expand = expand_scale(0)) +
  xlab('deaths per 10,000 inhabitants') + ylab('number of counties')
```

Bias
: The difference between the truth and your estimate, on average.

Variance
: How much does your estimate vary around the truth, on average.

Over-fitting and Under-fitting
: Using too complex (over) or too simple (under) a method of analysis for the amount of data you have.

Power law
: a relationship wherein a relative change in one quantity results in a proportional relative change in the other quantity. For example, the side-length and the area of a square follow a power law relationship.

Correlation vs. Causation
: correlation measures the strength of a linear association between two quantities. Contrast this with the statement that manipulating one quantity results in a meaningful change in the other

Hidden common causes
: It is difficult to determine if one thing causes another purely through observation. We need to manipulate one to watch for an effect. If we simply observe, it is hard to rule out hidden factors that may cause both to change.

Bayesian
: Using "prior" information to think about predictions and uncertainty. As we collect data, we update our existing beliefs to incorporate this new evidence into our understanding.

Sampling
: How are the data collected? Some different types of samples are the _random sample_ or the _convenience sample_.

Sampling Frame
: The collection of all possible individuals (or objects or ...) that can be selected to be part of a sample. The Census draws _every_ person in the frame (all people in the US).

Confirmation bias
: The tendency to search for, interpret, favor, and recall information in a way that confirms or strengthens one's prior personal beliefs or hypotheses.


